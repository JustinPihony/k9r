@(projectDescription: ProjectDescription)

import org.apache.spark.{SparkConf, SparkContext}
import org.apache.spark.SparkContext._
import org.apache.spark.sql.SQLContext

package @{projectDescription.organization}.@{projectDescription.name.toLowerCase}

object @{projectDescription.name} {

  def main(argv: Array[String]): Unit = {
    println("Hello from @{projectDescription.name}'s for Spark:")
    val conf = new SparkConf()
    conf.setMaster("local[*]")
    conf.setAppName("@{projectDescription.name}")
    // Change to a more reasonable default number of partitions for our data
    // (from 200)
    conf.set("spark.sql.shuffle.partitions", "4")
    val sc = new SparkContext(conf)
    val sqlContext = new SQLContext(sc)
    import sqlContext.implicits._

    // Your code here...
  }
}